\documentclass[10pt, a4paper]{article}
\author{}
\usepackage[top=2.5cm, bottom=3cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd, fancyhdr, color, comment, graphicx, environ}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage[dvipsnames]{xcolor}
\usepackage{xcolor}
\definecolor{dark}{RGB}{0,0,0}
\definecolor{verbatimgray}{RGB}{245,245,245}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage[english]{babel}
\usepackage{listings}
\lstset{
    basicstyle=\small\ttfamily,
    breaklines=true,
    breakindent=0pt,
    backgroundcolor=\color{verbatimgray},
    framexleftmargin=10pt,  
    framexrightmargin=10pt,
    xleftmargin=10pt,
    xrightmargin=10pt, 
    columns=fullflexible
}
\usepackage{sectsty}
\usepackage{thmtools}
\usepackage{shadethm}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{algorithm2e}
\usepackage{fancybox}
\usepackage[T1]{fontenc}
\usepackage{mdframed}
\usepackage{csquotes}
\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\setlength{\parskip}{0.3\baselineskip plus \smallskipamount minus \smallskipamount}
\setlength{\parindent}{10pt}
\setlist[itemize]{parsep=0pt, noitemsep, topsep=0pt}
\setlist[enumerate]{parsep=0pt}

\hypersetup{
    colorlinks=true,
    linkcolor=dark,
    filecolor=magenta,      
    urlcolor=blue,
}

\pagestyle{fancy}
\headheight 35pt
\lhead{\includegraphics[height=1.3cm]{lulea-tekniska-universitet-logo.png}}
\lfoot{}
\pagenumbering{arabic}
\cfoot{\small\thepage}
\rfoot{}
\headsep 1.2em
\renewcommand{\baselinestretch}{1.25}     
\mdfdefinestyle{theoremstyle}{
linecolor=black,linewidth=1pt,
frametitlerule=true,
frametitlebackgroundcolor=gray!20,
innertopmargin=\topskip,
}  

\usepackage{tocloft}
\setlength{\cftparskip}{1pt}
 
\begin{document}
    \begin{titlepage}      
        \begin{center}
            \includegraphics[width=0.4\textwidth]{lulea-tekniska-universitet-logo.png}\\[4cm]
            \huge{Mini Project : Development of 4 classification models for 20 datasets}\\[1cm]
            \linespread{1.2}\large { BOURGUEIL Pierre, DAPONTE Tanguy, DUFLOS Emilie, GABORIT Nawen}\\[0.5cm]
            \linespread{1}~\\[2cm]
            {\Large D7041E, Applied Artificial Intelligence, Lp2, H24}    
            \vfill
            \today
        \end{center}
    \end{titlepage}

\newpage

\tableofcontents
\newpage

\section{Grading criteria}
For this project, we will develop two unsupervised models and two supervised models to classify 20 datasets from the 121 UCI datasets (\href{https://archive.ics.uci.edu/datasets}{Available here})

\section{Chosen datasets}
To select our datasets, we looked at the first 30 datasets from the UCI ML Repository and used the following criteria:
\begin{itemize}
    \item 1K to 10K instances
    \item 10 to 4K features
    \item available for python import
\end{itemize}
Finally, we removed the datasets containing missing values or errors and ended up with the 22 following datasets (the number is the ID of the dataset):
\begin{itemize}
    \item "wine quality" : 186
    \item "predict students dropout and academic success": 697
    \item "estimation of obesity levels based on eating habits and physical condition": 544
    \item "spambase": 94
    \item "seoul bike sharing demand": 560
    \item "optical recognition of handwritten digits": 80
    \item "parkinsons telemonitoring": 189
    \item "aids clinical trials group study 175": 890
    \item "iranian churn": 563
    \item "taiwanese bankruptcy prediction": 572
    \item "room occupancy estimation": 864
    \item "solar flare": 89
    \item "image segmentation": 50
    \item "website phishing": 379
    \item "steel plates faults": 198
    \item "hepatitis c virus hcv for egyptian patients": 503
    \item "statlog landsat satellite": 146
    \item "isolet": 54
    \item "chess king rook vs king pawn": 22
    \item "waveform database generator version 1": 107
    \item "page blocks classification": 78
    \item "musk version 2": 75
    \item "statlog image segmentation": 147
\end{itemize}
\newpage

\section{Used models}
\subsection{Supervised models}

\begin{itemize}
    \item Decision Tree Classifier
    
    A decision tree classifier (\href{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier}{sklearn documentation}) models data using a tree-like structure, where each internal node represents a decision based on a feature, and each leaf node represents the output or predicted class.

    \item Support Vector Classifier
    
    Another very used model for supervised classification is the SVC (\href{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC}{sklearn documentation}). It works by finding the hyperplane that separates best the data points of each classes, maximizing the margin between the closest points of each class, called support vectors. 
    
\end{itemize}

\subsection{Unsupervised models}
We selected two unsupervised models : KMeans and DBSCAN.
\begin{itemize}
    \item KMeans
    
    We used the scikit-learn implementation of KMeans (\href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans}{link to documentation}). KMeans partitions the data points of a dataset into k clusters (k has to be defined). The algorithm is called K-Means because a centroid (center of the cluster) is the mean of all the points in the cluster. Points are assigned to clusters (nearest centroid) and then the centroids are recalculated until the convergence (centroids don't change significantly anymore).


    \item DBSCAN
    
    We also used the implementation of sklearn (\href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{link to documentation}). DBSCAN or Density-Based Spatial Clustering of Applications with Noise is a clustering algorithm that groups data points close to each other. If the distance between 2 points is lower or equal to the epsilon defined then they are considered neighbors and are assigned to the same cluster. Some points are assigned as noisy points (not in any cluster).
\end{itemize}
\newpage

\section{Experimental methodology}
\subsection{Data preprocessing}
Before training the models, we preprocessed all the datasets. Each dataset was loaded, encoded, normalized and then we applied PCA to reduce the size. The encoding of a dataset consist in managing the values such as date or time and for some specific datasets, mapping the categorical values into numerical values. For example, if in a dataset, one feature took the values 'yes' or 'no', it became 1 or 0 (one hot encoding).
After, the datasets are normalized using the function MinMaxScaler().
Then, Principal Components Analysis is applied to reduce the number of features but keep the maximum variance ratio possible.

\subsection{Train Test Split}
For the supervised models, we separated each dataset into a train part (80\%) and a test part(20\%), we trained the model using the train part and then predicted using the test set and evaluated the performance with this prediction.

\subsection{Training}
After all the preprocessing of the dataset, the models can be trained on the data.

\subsection{Metrics}
To evaluate the performance of our models on each dataset we used the accuracy (difference between the true labels and the predicted ones) for the supervised models and rand score (it is a similarity measure between two clusterings, see \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score}{sklearn documentation} for more precision) for the unsupervised. We chose the rand score for the unsupervised since the labels predicted are not always the same as the true labels but can correspond to the same class.
\newpage

\section{Results}

\subsection{Decision Tree Classifier}

When executing the code, we obtain the following results (the results in the table correspond to the decision tree model) :


\begin{tabular}{cccc}
   & dataset id                                            &   name & accuracy \\
0     &     186         &                             wine quality & 0.591538 \\
1     &     697     & predict students dropout and academic success & 0.638418 \\
2     &    544  & estimation of obesity levels based on eating h & 0.711584 \\
3     &     94   &                                       spambase & 0.879479 \\
4     &    560   &                      seoul bike sharing demand & 0.976598 \\
5     &     80   &      optical recognition of handwritten digits & 0.859431 \\
6     &    189   &                      parkinsons telemonitoring & 0.211915 \\
7     &    890   &           aids clinical trials group study 175 & 0.742991 \\
8     &    563   &                                  iranian churn & 0.914286 \\
9    &    572    &               taiwanese bankruptcy prediction & 0.934018 \\
10   &     864   &                      room occupancy estimation & 0.975814 \\
11   &      89   &                                    solar flare & 0.816547 \\
12   &      50   &                             image segmentation & 0.761905 \\
13   &     379   &                               website phishing & 0.833948 \\
14   &     198   &                            steel plates faults & 0.899743 \\
15   &     503   &    hepatitis c virus hcv for egyptian patients & 0.267148 \\
16   &     146   &                      statlog landsat satellite & 0.857809 \\
17   &      54   &                                         isolet & 0.667949 \\
18   &      22   &                   chess king rook vs king pawn & 0.867188 \\
19   &     107   &          waveform database generator version 1 & 0.817000 \\
20   &      78   &                     page blocks classification & 0.950685 \\
21   &      75   &                                 musk version 2 & 0.926515 \\
22   &     147   &                     statlog image segmentation & 0.909091 \\
\end{tabular}


\begin{itemize}
    \item Average accuracy for Decision Tree : 0.783
    \item Average accuracy for SVC : 0.829
\end{itemize}


Overall, the SVC performs better than the Decision Tree Classifier; however, for some specific cases the decision tree is more adapted and the accuracy is higher than the support vector classifier. 

\begin{itemize}
    \item Average Rand Index for KMeans : 0.626
    \item Average Rand Index for DBSCAN : 0.458
\end{itemize}


When analyzing more the results, we can see that even if DBSCAN don't have a good performance overall, for some datasets the results are good, for example "seoul bike sharing demand" with an index of 0.93. Indeed, DBSCAN is very sensitive to its hyperparameters and especially epsilon, since we kept the same value for every dataset, it was not adapted to some of them. Moreover, DBSCAN handles noise, which is an advantage in some specific cases but not in ours. The Kmeans' performance is better overall even if we needed to specify the number of clusters in the beginning.

\newpage
\section{Conlusion}
%
\end{document}